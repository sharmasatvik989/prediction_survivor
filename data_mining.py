# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AbFPu-3QQ6ewO-yvVMBy3I3BoMJr00e0
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.tree import DecisionTreeClassifier

cd '/content/drive/MyDrive/data_mining/'

"""The code line uses the mounted drive data folder to read the data, if you dont want to mount just simply paste the data on google collab and copy the file pathcode onto the below line for train data.
And below that copy the file path for the test data to read from it.
"""

train_data = pd.read_csv('dataset/train.csv')
train_data.head()

"""As we can see from the trsin data set the columns **Pclass** will show whether the passenger is rich or poor.
Secondly, Using **Age** column we can see that passengers who survived are young/middle/old.
Lastly **Sex** column will show that whether the passenger survived is male or female.

Using the train data set we can refer and predict whether the passenger will survive or not on the test data.
"""

test_data = pd.read_csv('dataset/test.csv')
test_data.head()

"""Below we will preprocess and understand the training data."""

train_data.describe()

a = train_data.isnull().sum()
print(a)

train_data.shape

"""The output shows what is the shape of the data. And as you can see there are **891** passengers in the train data.

"""

train_data.dropna(subset = ["Age"], inplace=True)

"""The implementation will drop all the Nan values of Age as if we try and fill the Nan values with mean or mode the result can be deviated from original."""

train_data.shape

"""From above we can see the shape has now changed and the number of rows are now 714."""

train_data.isnull().sum()

"""Now it shows that there are no **Nan** values in the train data."""

survive_by_age = train_data[train_data['Survived'] == 1]
total_rows = survive_by_age['Survived'].count()
print(total_rows)

"""The data shows out that there are 290 rows out of 714 where the passenger survived.




"""

for index in train_data.index:
  
  if (train_data.loc[index,'Age'] > 0.0) and (train_data.loc[index,'Age'] <= 13.0):
    train_data.loc[index,'Age'] = 1
  elif (train_data.loc[index,'Age'] > 13.0) and (train_data.loc[index,'Age'] <= 40):
    train_data.loc[index,'Age'] = 2
  elif (train_data.loc[index,'Age'] > 40) and (train_data.loc[index,'Age'] <= 100.0):
    train_data.loc[index,'Age'] = 3

"""I will the change the values of the column **Age** as it needs classification to determine which group of people survived the most. 
I will classify in 1 , 2 , 3 where 1 being **Young**, 2 is **Middle** and 3 is **Old**.
"""

x = sum(train_data['Age'] == 1)
print(x)

y = sum(train_data['Age'] == 2)
print(y)

z = sum(train_data['Age'] == 3)
print(z)

"""After classication of the Age column we have 71 young people , 493 middle people and 150 old people."""

age_1 = survive_by_age['Survived'][train_data['Age'] == 1]
value_1 = sum(age_1)

sur_rate_1 = (value_1/290)*100
print("The survival rate of Young passegers is",sur_rate_1,"%")

age_2 = survive_by_age['Survived'][train_data['Age'] == 2]
value_2 = sum(age_2)

sur_rate_2 = (value_2/290)*100
print("The survival rate of middle passegers is",sur_rate_2,"%")


age_3 = survive_by_age['Survived'][train_data['Age'] == 3]
value_3 = sum(age_3)

sur_rate_3 = (value_3/290)*100
print("The survival rate of old passegers is",sur_rate_3,"%")

"""After preprocessing the data we identified that out of 714 passengers 290 survived and out of those passenger with id 1 coming under young category 42 of those survived, 193 middle age passenger survived and 55 old passenger survived."""

Age = ['Young','Middle','Old']
Survival_value = [value_1,value_2,value_3]

colors = ['r', 'y', 'g', 'b']
plt.pie(Survival_value, labels = Age, colors=colors)
plt.legend()

plt.show()

"""From the pie chart we can see that Middle age passengers survived the highest and it can used to predict the data."""

sns.barplot(x="Sex", y="Survived", hue="Sex", data=train_data)

"""Using the bar plot we figure out that of those female were the highest survived passenger.

"""

women = train_data.loc[train_data.Sex == 'female']["Survived"]
rate_women = sum(women)/len(women)

men = train_data.loc[train_data.Sex =='male']["Survived"]
rate_men = sum(men)/len(men)

print("% of women who survived:\n", rate_women)
print("% of men whoe survived:\n",rate_men)

x = sum(train_data['Pclass'] == 1)
print(x)

y = sum(train_data['Pclass'] == 2)
print(y)

z = sum(train_data['Pclass'] == 3)
print(z)

pclass_1 = survive_by_age['Survived'][train_data['Pclass'] == 1]
p_1 = sum(pclass_1)

sur_plc_1 = (p_1/290)*100
print("The survival rate of first class passegers is",sur_plc_1,"%")

pclass_2 = survive_by_age['Survived'][train_data['Pclass'] == 2]
p_2 = sum(pclass_2)

sur_plc_2 = (p_2/290)*100
print("The survival rate of second class passegers is",sur_plc_2,"%")

pclass_3 = survive_by_age['Survived'][train_data['Pclass'] == 3]
p_3 = sum(pclass_3)

sur_plc_3 = (p_3/290)*100
print("The survival rate of third class passegers is",sur_plc_3,"%")

pcl = ['First','second','third']
Survival_value_p = [p_1,p_2,p_3]

colors = ['r', 'y', 'g', 'b']
plt.pie(Survival_value_p, labels = pcl, colors=colors)
plt.legend()

plt.show()

"""From the pie we figure out that First class passengers survived the most.

Now we will move forward to read from the test data and predict using random forest classifier.
"""

a = test_data.isnull().sum()
print(a)

test_data.shape

test_data.dropna(subset = ["Age"], inplace=True)

test_data.shape

for index in test_data.index:
  
  if (test_data.loc[index,'Age'] > 0.0) and (test_data.loc[index,'Age'] <= 13.0):
    test_data.loc[index,'Age'] = 1
  elif (test_data.loc[index,'Age'] > 13.0) and (test_data.loc[index,'Age'] <= 40):
    test_data.loc[index,'Age'] = 2
  elif (test_data.loc[index,'Age'] > 40) and (test_data.loc[index,'Age'] <= 100.0):
    test_data.loc[index,'Age'] = 3

"""For the test data to use random forest classifier and predict for the survival in the test data we have to features for the decision tree and since we have to use age as a feature in both the data set I have preprocessed the **Age** data to have only three nodes classifying it into three categories i.e, young, middle and old.
Using the data preprocessing and using **Age** as a feature I have used random forest classifier to predict on the test data.
"""

features = ["Pclass", "Sex", "Age","SibSp"]

X = pd.get_dummies(train_data[features])
y = train_data["Survived"]

model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)
model.fit(X, y)

X_test = pd.get_dummies(test_data[features])
rf_predictions = model.predict(X_test)
print("Random forest Accuracy with 4 features : ", round(model.score(X, y)*100, 2))

output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': rf_predictions})
output.to_csv('my_submission.csv', index=False)
print("Your submission was successfully saved!")

"""The code uses 4 feature in the random forest classifier and predciton holds an accuracy of 83.75%."""